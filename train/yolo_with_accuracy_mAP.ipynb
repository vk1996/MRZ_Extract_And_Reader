{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ul6riFlyoeqb",
    "outputId": "36c2693d-ad33-4bbf-b9a0-2277603e5592"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxAuli-xxJEb"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/drive/MyDrive/vignesh/ps/colab/* /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-VR7dKtNq4b"
   },
   "outputs": [],
   "source": [
    "!unzip -q '/content/drive/MyDrive/vignesh/ps/syn_data.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pGFU3p2fYjT"
   },
   "outputs": [],
   "source": [
    "#!pip3 install tensorflow==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYojgOO2b37A"
   },
   "outputs": [],
   "source": [
    "!pip3 install albumentations==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GD2cmQzMcBec",
    "outputId": "a6fceb5f-63f9-48cb-9228-b12999853b16"
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "import albumentations as A\n",
    "from albumentations import BboxParams\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from yolotxt2rectangle import yolotxt2rectangle\n",
    "from tensorflow.keras.applications import MobileNetV3Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Inp1l-8cQAP",
    "outputId": "db20b763-3b7c-4264-8218-debc8d927fca"
   },
   "outputs": [],
   "source": [
    "#globals \n",
    "# n_classes is 1 higher than YOLO since class  0 is background in SSD\n",
    "size=(784,784,3)\n",
    "colormode='rgb'\n",
    "normalize_factor=1/255.\n",
    "width=size[0]\n",
    "height=size[1]\n",
    "channels=size[2]\n",
    "batch_size=16\n",
    "grid_size_w=96.0\n",
    "grid_size_h=96.0\n",
    "grid_factor_w=1/grid_size_w\n",
    "grid_factor_h=1/grid_size_h\n",
    "with open('classes.txt','r') as f:\n",
    "    data=f.read()\n",
    "LABELS=[i for i in data.split('\\n') if len(i)>0]\n",
    "nclasses=len(LABELS)\n",
    "print('num classes:',nclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Fa_h-IWY8Xk",
    "outputId": "1c4905d8-3e92-4547-b5f7-81e82bae5ecc"
   },
   "outputs": [],
   "source": [
    "train_fnames=sorted(glob('data/ab_full/train/*.txt'))+sorted(glob('data/ab_full/upsample/*.txt'))\n",
    "val_fnames=sorted(glob('data/ab_full/test/*.txt'))\n",
    "test_fnames=val_fnames\n",
    "print('Num train files:',len(train_fnames))\n",
    "print('Num val files:',len(val_fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9_8p_0uetnu"
   },
   "outputs": [],
   "source": [
    "class datagen(Sequence):\n",
    "\n",
    "  def __init__(self,train_im_path,augmentations):\n",
    "    self.batch_size=batch_size\n",
    "    self.train_im_paths=train_im_path\n",
    "    self.img_size=size\n",
    "    print(self.img_size)\n",
    "    self.nchannels=channels\n",
    "    self.shuffle=shuffle\n",
    "    self.augmentations=augmentations\n",
    "    self.grid_size_w=grid_size_w\n",
    "    self.grid_size_h=grid_size_h\n",
    "    self.info=5\n",
    "    if self.augmentations!=None:\n",
    "      print('Augs used:',self.augmentations)\n",
    "    self.on_epoch_end()\n",
    "    print('Num images found : {}'.format(len(self.train_im_paths)))\n",
    "\n",
    "  def __len__(self):\n",
    "    return int(np.ceil(len(self.train_im_paths) / self.batch_size))\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "    if self.augmentations!=None:\n",
    "      self.aug=self.get_aug(self.augmentations)\n",
    "    indexes = self.indexes[index*self.batch_size:min((index+1)*self.batch_size,len(self.train_im_paths))]\n",
    "\n",
    "    list_IDs_im = [self.train_im_paths[k] for k in indexes]\n",
    "    \n",
    "    try:\n",
    "      X,y= self.data_generation(list_IDs_im,colormode)\n",
    "    except ValueError:\n",
    "      #print(list_IDs_im,)\n",
    "      print('problem averted')\n",
    "      X,y=self.prev_X,self.prev_Y\n",
    "\n",
    "    self.prev_X,self.prev_Y=X,y\n",
    "    return X,y\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "    self.indexes = np.arange(len(self.train_im_paths))\n",
    "    if self.shuffle == True:\n",
    "      np.random.shuffle(self.indexes)\n",
    "\n",
    "  def get_aug(self,aug, min_area=0., min_visibility=0.):\n",
    "    return A.Compose(aug, A.BboxParams(format='pascal_voc', min_area=min_area, \n",
    "                                       min_visibility=min_visibility, label_fields=['category_id']))\n",
    "  \n",
    "  def data_generation(self,list_IDs,color_mode):\n",
    "    \n",
    "\n",
    "    X = []\n",
    "\n",
    "    Y = np.zeros((len(list_IDs),int(self.grid_size_h),int(self.grid_size_w), 1, nclasses + self.info))\n",
    "\n",
    "    for count,i in enumerate(list_IDs):\n",
    "      #print('filename:',i)\n",
    "      self.curr_name=i\n",
    "      self.flag=False\n",
    "      \n",
    "    \n",
    "      if os.path.exists(i[:-4]+'.jpg'):\n",
    "        x=cv2.resize(cv2.imread(i[:-4]+'.jpg'),(width,height),interpolation=cv2.INTER_AREA)\n",
    "        x=cv2.cvtColor(x,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "      if os.path.exists(i[:-4]+'.png'):\n",
    "        x=cv2.resize(cv2.imread(i[:-4]+'.png'),(width,height),interpolation=cv2.INTER_AREA)\n",
    "        x=cv2.cvtColor(x,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "       \n",
    "      #print(box)\n",
    "      box=yolotxt2rectangle(i,y_height=height,x_height=width,last_class=0)\n",
    "      self.curr_box=box\n",
    "\n",
    "\n",
    "      if self.augmentations!=None:\n",
    "\n",
    "       \n",
    "        annotations = {'image': x, 'bboxes': [i for i in box[:,1:]], 'category_id': [i for i in box[:,0]]}\n",
    "        augmented = self.aug(**annotations)\n",
    "        x=augmented['image']\n",
    "\n",
    "        box_array=np.empty(shape=(len(augmented['bboxes']),5))\n",
    "        box_array[:,1:]=np.array(augmented['bboxes'])\n",
    "        box_array[:,0]=np.array(augmented['category_id'])\n",
    "        box=box_array.copy()\n",
    "\n",
    "      x=np.expand_dims(x,axis=0)\n",
    "      self.curr_frame=x\n",
    "      #print(x.shape)\n",
    "      X.append(x)\n",
    "        \n",
    "      #print('Num boxes:',len(box))\n",
    "        \n",
    "      coords=[]\n",
    "\n",
    "      \n",
    "      for label, bndbox in zip(box[:,0],box[:,1:]):\n",
    "          xmin = int(bndbox[0])\n",
    "          ymin = int(bndbox[1])\n",
    "\n",
    "          xmax = int(bndbox[2])\n",
    "          ymax = int(bndbox[3])\n",
    "\n",
    "          w = (xmax - xmin) / width\n",
    "          h = (ymax - ymin) / height\n",
    "\n",
    "          cx = ((xmax + xmin) / 2) / width\n",
    "          cy = ((ymax + ymin) / 2) / height\n",
    "\n",
    "          \n",
    "\n",
    "          cx = cx * self.grid_size_w\n",
    "          cy = cy * self.grid_size_h\n",
    "            \n",
    "          if (int(cy), int(cx),0) in coords:\n",
    "            print('Duplicate:',(int(cy), int(cx)),i)  \n",
    "            plt.imshow(x.squeeze())\n",
    "            plt.show()\n",
    "                \n",
    "          else:\n",
    "            \n",
    "            Y[count,int(cy), int(cx), 0, 0] = 1 #objectness\n",
    "            Y[count,int(cy), int(cx), 0, 1] = cx - int(cx)\n",
    "            Y[count,int(cy), int(cx), 0, 2] = cy - int(cy)\n",
    "            Y[count,int(cy), int(cx), 0, 3] = w\n",
    "            Y[count,int(cy), int(cx), 0, 4] = h\n",
    "        \n",
    "            coords.append((int(cy), int(cx),0))\n",
    "\n",
    "          \n",
    "\n",
    "          class_index = int(label)\n",
    "          Y[count,int(cy), int(cx), 0, 5 + class_index] = 1.0\n",
    "\n",
    "    \n",
    "    X=np.array(X).squeeze()\n",
    "\n",
    "    return X*normalize_factor,Y\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9kuzs8mNvao"
   },
   "outputs": [],
   "source": [
    "!mkdir encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ml_Yn0BXezTB"
   },
   "outputs": [],
   "source": [
    "augmentations=[\n",
    "               A.ShiftScaleRotate(rotate_limit=5,p=0.3,border_mode=cv2.BORDER_CONSTANT,mask_value=0,scale_limit=0.05,shift_limit=0.05),\n",
    "               A.RandomBrightnessContrast(p=0.2),\n",
    "               A.HorizontalFlip(p=0.3),\n",
    "               A.VerticalFlip(p=0.3),\n",
    "               A.RandomSunFlare(p=0.3,src_radius=150,flare_roi=(0, 0, 1,1),src_color=(224,224,224)),\n",
    "               A.ChannelShuffle(p=0.3)\n",
    "               ] \n",
    "augmentations=None\n",
    "val_augmentations=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMJpeisTfFeG",
    "outputId": "5a059ea0-b900-4632-82a2-3352c886bfc8"
   },
   "outputs": [],
   "source": [
    "#train_im_path,augmentations,batch_size,nclasses,num_boxes,predictor_sizes,img_size=256,nchannels=3,normalize_img=False,shuffle=True\n",
    "gen=datagen(shuffle(train_fnames),None)\n",
    "aug_gen=datagen(shuffle(train_fnames),augmentations)\n",
    "valgen=datagen(val_fnames,val_augmentations)\n",
    "testgen=datagen(val_fnames,val_augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "_x14OcNbfJ0h",
    "outputId": "558f077f-c691-4e5a-f288-19aaf807c384"
   },
   "outputs": [],
   "source": [
    "for id_ in range(len(aug_gen)):\n",
    "\n",
    "  #id_=np.random.randint(0,len(aug_gen))\n",
    "  # #id_=18\n",
    "  #print(id_)\n",
    "\n",
    "\n",
    "  img,arr=aug_gen[id_]\n",
    "#   grid_w=arr.shape[1]\n",
    "#   grid_h=arr.shape[2]\n",
    "#   #print(img.shape,arr.shape)\n",
    "#   for batch in range(len(arr)):\n",
    "#     num_boxes=0\n",
    "#     for k in range(1):\n",
    "#         for i in range(grid_w):\n",
    "#           for j in range(grid_h):\n",
    "#             confidence = arr[batch,i, j, k, 0].squeeze()\n",
    "\n",
    "\n",
    "\n",
    "#             if confidence==1.0:\n",
    "#               num_boxes+=1\n",
    "#               cx,cy,w,h=arr[batch,i, j, k,1:5]\n",
    "\n",
    "#               cx = ((j + (cx)) / grid_size_w)\n",
    "#               cy = ((i + (cy)) / grid_size_h)\n",
    "\n",
    "#               cx=cx*width\n",
    "#               cy=cy*height\n",
    "#               w=w*width\n",
    "#               h=h*height\n",
    "\n",
    "#               xmin=int(cx-(w/2))\n",
    "#               ymin=int(cy-(h/2))\n",
    "#               xmax=int(cx+(w/2))\n",
    "#               ymax=int(cy+(h/2))\n",
    "\n",
    "\n",
    "#               text=LABELS[int(np.argmax(arr[batch,i, j, 0, 5:]))]\n",
    "\n",
    "#               cv2.rectangle(img[batch], (int(xmin),int(ymin)), (int(xmax),int(ymax)), (0,0,0), 2)\n",
    "#               #cv2.putText(img[batch], text, (int(cx) - 10, int(cy) - 10),cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,0,0), 1)\n",
    "    \n",
    "\n",
    "#     plt.imshow(img[batch])\n",
    "#     plt.show()\n",
    "#   #329881_1_4787779\n",
    "\n",
    "# #Duplicate: (67, 51) data/ab_full/midv_train/DG16_17.txt\n",
    "#20201203_171818_PASSPORT_5fc8bb6acdb35456492104b6_d37b6358-004b-4f78-a315-507ca7f1427f_frontImage_1_1347339.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_ in range(len(valgen)):\n",
    "\n",
    "  #id_=np.random.randint(0,len(aug_gen))\n",
    "  # #id_=18\n",
    "  #print(id_)\n",
    "\n",
    "\n",
    "  img,arr=valgen[id_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6VlhbNiefWLd",
    "outputId": "409e7d2c-9573-4e9f-ac10-aab62473a18f"
   },
   "outputs": [],
   "source": [
    "# id_=np.random.randint(0,len(valgen))\n",
    "# #id_=211\n",
    "# print(id_)\n",
    "# img,arr=valgen[id_]\n",
    "# grid_w=arr.shape[1]\n",
    "# grid_h=arr.shape[2]\n",
    "# print(img.shape,arr.shape)\n",
    "# for batch in range(len(arr)):\n",
    "\n",
    "#   for i in range(grid_w):\n",
    "#     for j in range(grid_h):\n",
    "#       confidence = arr[batch,i, j, 0, 0].squeeze()\n",
    "\n",
    "#       if confidence==1.0:\n",
    "#         cx,cy,w,h=arr[batch,i, j, 0,1:5]\n",
    "        \n",
    "#         cx = ((j + (cx)) / grid_size_w)\n",
    "#         cy = ((i + (cy)) / grid_size_h)\n",
    "\n",
    "#         cx=cx*width\n",
    "#         cy=cy*height\n",
    "#         w=w*width\n",
    "#         h=h*height\n",
    "\n",
    "        \n",
    "\n",
    "#         xmin=int(cx-(w/2))\n",
    "#         ymin=int(cy-(h/2))\n",
    "#         xmax=int(cx+(w/2))\n",
    "#         ymax=int(cy+(h/2))\n",
    "\n",
    "\n",
    "#         text=LABELS[int(np.argmax(arr[batch,i, j, 0, 5:]))]\n",
    "\n",
    "#         cv2.rectangle(img[batch], (int(xmin),int(ymin)), (int(xmax),int(ymax)), (0,0,0), 2)\n",
    "#         cv2.putText(img[batch], text, (int(cx) - 10, int(cy) - 10),cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,0,0), 1)\n",
    "  \n",
    "  \n",
    "#   #print(img[batch].shape)\n",
    "#   if colormode==\"grayscale\":\n",
    "#     plt.imshow(img[batch],cmap='gray')\n",
    "#   else:\n",
    "#     plt.imshow(img[batch])\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6625YLmhhQW",
    "outputId": "2a4c6707-6d4e-4050-d45a-7e6c9b9f7b9f"
   },
   "outputs": [],
   "source": [
    "img.shape,arr.shape,img.max(),normalize_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Np_WsmODkvEE"
   },
   "outputs": [],
   "source": [
    "def multiboxes_loss(y_true, y_pred):\n",
    "    l_coords = 5.0\n",
    "    l_noob = 0.5\n",
    "    coords = y_true[:, :, :, :, 0] * l_coords\n",
    "\n",
    "    noobs = -1 * (y_true[:, :, :, :, 0] - 1) * l_noob\n",
    "    p_pred = y_pred[:, :, :, :, 0]\n",
    "    p_true = y_true[:, :, :, :, 0]\n",
    "    x_true = y_true[:, :, :, :, 1]\n",
    "    x_pred = y_pred[:, :, :, :, 1]\n",
    "    yy_true = y_true[:, :, :, :, 2]\n",
    "    yy_pred = y_pred[:, :, :, :, 2]\n",
    "    w_true = y_true[:, :, :, :, 3]\n",
    "    w_pred = y_pred[:, :, :, :, 3]\n",
    "    h_true = y_true[:, :, :, :, 4]\n",
    "    h_pred = y_pred[:, :, :, :, 4]\n",
    "\n",
    "    cl_true = y_true[:, :, :, :, 5:]\n",
    "    cl_pred = y_pred[:, :, :, :, 5:]\n",
    "\n",
    "    p_loss_absent = K.sum(K.square(p_pred - p_true) * noobs)\n",
    "    p_loss_present = K.sum(K.square(p_pred - p_true))\n",
    "    x_loss = K.sum(K.square(x_pred - x_true) * coords)\n",
    "    yy_loss = K.sum(K.square(yy_pred - yy_true) * coords)\n",
    "    xy_loss = x_loss + yy_loss\n",
    "    w_loss = K.sum(K.square(K.sqrt(w_pred) - K.sqrt(w_true)) * coords)\n",
    "    h_loss = K.sum(K.square(K.sqrt(h_pred) - K.sqrt(h_true)) * coords)\n",
    "    wh_loss = w_loss + h_loss\n",
    "\n",
    "    cl_loss = K.sum(K.square(cl_true - cl_pred))\n",
    "    loss = p_loss_absent + p_loss_present + xy_loss + wh_loss + cl_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0zuwSdNfht_f",
    "outputId": "20b30c1e-9384-4a40-94f5-883636b9c030"
   },
   "outputs": [],
   "source": [
    "def yolo_model(input_shape, classes, info=5):\n",
    "    K.clear_session()\n",
    "    inp = Input(input_shape)\n",
    "\n",
    "    \n",
    "    base_model = MobileNetV3Large(input_tensor=inp,\n",
    "                                  include_top=False, \n",
    "                                  weights='imagenet'\n",
    "                                  )\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "      layer.trainable=True\n",
    "    \n",
    "\n",
    "    #fe_layer = base_model.layers[-7].output\n",
    "\n",
    "    fe_layer = base_model.get_layer('multiply_13').output\n",
    "\n",
    "\n",
    "    conv = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(fe_layer)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0.275)(conv)\n",
    "    conv= UpSampling2D()(conv)\n",
    "\n",
    "    conv = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0.275)(conv)\n",
    "    conv= UpSampling2D()(conv)\n",
    "    \n",
    "    conv = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = LeakyReLU(alpha=0.275)(conv)\n",
    "    #conv= UpSampling2D()(conv)\n",
    "\n",
    "    conv = Conv2D(classes + info, (3, 3), activation=\"sigmoid\", padding=\"same\")(conv)\n",
    "\n",
    "    output = Reshape((int(grid_size_h),int(grid_size_w), 1, classes + info))(conv)\n",
    "    model = Model(inp, output)\n",
    "\n",
    "    return model\n",
    "\n",
    "model=yolo_model(size,nclasses)\n",
    "# model=load_model('/content/drive/MyDrive/vignesh/field_detection/passport/deu/models/deupassportv1_yolo_90mAP42.0_acc100_wo.h5',custom_objects={\n",
    "#     'multiboxes_loss':multiboxes_loss\n",
    "# })\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSjPo03AkzWN"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=multiboxes_loss,optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWmo0ilDy4d0"
   },
   "outputs": [],
   "source": [
    "class mAP(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(mAP, self).__init__()\n",
    "        self.num_accurate=None\n",
    "        self.current_epoch=None\n",
    "        self.img_width=width\n",
    "        self.img_height=height\n",
    "        self.frame_width=None\n",
    "        self.frame_height=None\n",
    "        self.color_mode=colormode\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.nb_epoch = self.params['epochs']\n",
    "        \n",
    "        \n",
    "    def accumulate(self,filepath):\n",
    "\n",
    "      if os.path.exists(filepath[:-4]+'.jpg'):\n",
    "        src_img=cv2.imread(filepath[:-4]+'.jpg')\n",
    "      if os.path.exists(filepath[:-4]+'.png'):\n",
    "        src_img=cv2.imread(filepath[:-4]+'.png')\n",
    "      self.frame_width,self.frame_height=src_img.shape[1],src_img.shape[0]\n",
    "\n",
    "      img=cv2.resize(src_img,(width,height),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "      if self.color_mode==\"grayscale\":\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img=np.expand_dims(img,axis=-1)\n",
    "\n",
    "      else:\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "      blob=np.expand_dims(img,axis=0)*normalize_factor\n",
    "      iou_threshold=0.5\n",
    "      confidence_thresh=0.5\n",
    "\n",
    "      arr=model.predict(blob)\n",
    "\n",
    "\n",
    "      assert(os.path.exists('gt')),'No ground truth folder found'\n",
    "      shutil.copy(filepath[:-4]+'.txt','gt')\n",
    "      assert(os.path.exists('det')),'No detection folder found'\n",
    "\n",
    "\n",
    "      valid_boxes=[]\n",
    "\n",
    "\n",
    "      for batch in range(len(arr)):\n",
    "        \n",
    "        for i in range(grid_w):\n",
    "          \n",
    "          for j in range(grid_h):\n",
    "\n",
    "            confidence = arr[batch,i, j, 0, 0].squeeze()\n",
    "\n",
    "            if confidence>=0.25:\n",
    "              valid_boxes.append(arr[batch,i, j, 0,:])\n",
    "              cx,cy,w,h=arr[batch,i, j, 0,1:5]\n",
    "              \n",
    "              cx = ((j + (cx)) / grid_size)\n",
    "              cy = ((i + (cy)) / grid_size)\n",
    "\n",
    "              class_index=int(np.argmax(arr[batch,i, j, 0, 5:]))\n",
    "\n",
    "\n",
    "              with open('det/{}.txt'.format(filepath.split('/')[-1][:-4]),'a')as f:\n",
    "                \n",
    "                f.write(f'{class_index} {confidence} {cx} {cy} {w} {h} \\n')\n",
    "\n",
    "        gt=np.loadtxt(filepath).squeeze()\n",
    "\n",
    "        if len(gt.shape)<2:\n",
    "          gt=np.expand_dims(gt,axis=0)\n",
    "        \n",
    "        if len(valid_boxes)==len(gt):\n",
    "          self.num_accurate+=1\n",
    "\n",
    "\n",
    "      \n",
    "        \n",
    "    \n",
    "    def compute_mAP(self,filedir,reset=False):\n",
    "      if reset:\n",
    "        os.system('rm -r gt')\n",
    "        os.system('rm -r det')\n",
    "        os.system('mkdir gt')\n",
    "        os.system('mkdir det')\n",
    "\n",
    "\n",
    "      print('Num files:',len(val_fnames))\n",
    "      for file in val_fnames:\n",
    "          self.accumulate(file)\n",
    "          \n",
    "       \n",
    "      os.system('python3 pascalvoc.py -gt gt -det det -gtcoords rel -detcoords rel -t 0.9 -gtformat xywh -detformat xywh -imgsize {},{} -np'.format(width,height))\n",
    "      with open('results/results.txt','r') as f:\n",
    "          f=f.read()\n",
    "          print(f.split('\\n')[-3:])\n",
    "          return f.split('\\n')[-3].strip('mAP: %')\n",
    "          #return f.split('\\n')[-3].strip('mAP: %'),f.split('\\n')[7].strip('AP: %'),f.split('\\n')[32].strip('AP: %')\n",
    "\n",
    "\n",
    "        \n",
    "    def on_test_end(self, batch, logs=None):\n",
    "      # if self.current_epoch<10:\n",
    "      #   return\n",
    "      self.num_accurate=0\n",
    "      #print('val mAP:',self.compute_mAP('/content/val',reset=True))\n",
    "      testmAP=self.compute_mAP('test',reset=True)\n",
    "      current_accuracy=round((self.num_accurate/len(val_fnames))*100)\n",
    "      model_name='/content/drive/MyDrive/vignesh/ps/models/mrz_yolo_90mAP{}_acc{}.h5'.format(testmAP,current_accuracy)\n",
    "           \n",
    "      #float(testmAP)>=60 and \n",
    "\n",
    "      if float(testmAP)>=1 and current_accuracy>=99:\n",
    "        model.save(model_name.replace('.h5','_wo.h5'))\n",
    "        model.save(model_name,include_optimizer=False)\n",
    "      \n",
    "      print('test mAP:',testmAP)\n",
    "      print(f'Accuracy:{current_accuracy} samples_correct:{self.num_accurate}/{len(val_fnames)}')\n",
    "      self.num_accurate=0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "      self.current_epoch=epoch\n",
    "      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FU4jvjAZJmpN",
    "outputId": "0fdf8792-e77c-4fb3-c7e4-63e2123e7b2a"
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4HVdj1PIL0v"
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr,5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "GUYMbFaZg6qm",
    "outputId": "2fd8ee60-4a94-4657-de97-0d8c5aad0bae"
   },
   "outputs": [],
   "source": [
    "initial_epoch=5\n",
    "final_epoch=2000\n",
    "print('lr:',K.eval(model.optimizer.lr))\n",
    "print('augs used:',augmentations)\n",
    "print('val_augs used:',val_augmentations)\n",
    "print('num train samples:',len(aug_gen)*batch_size)\n",
    "history=model.fit_generator(aug_gen,steps_per_epoch=len(aug_gen),\n",
    "                            epochs=final_epoch,\n",
    "                            initial_epoch=initial_epoch,\n",
    "                            validation_data=valgen,\n",
    "                            validation_steps=len(valgen),\n",
    "                            callbacks=None,\n",
    "                            #callbacks=[mAP()],\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "raNWBqgdt_aX",
    "outputId": "1ef4b95e-0bb5-4a13-a399-88f0813f8992"
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(valgen,\n",
    "                        callbacks=[mAP()],\n",
    "                         verbose=1,steps=len(valgen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLt46Xgje1q_"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/vignesh/field_detection/idcard_reduced/countrywise/uaeid/models/uaeid_yolo_temp_wo.h5',include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-2oxj0svsaQ"
   },
   "outputs": [],
   "source": [
    "for name in shuffle(test_fnames):\n",
    "  print(name)\n",
    "  img=cv2.imread(name.replace('txt','jpg'))\n",
    "  if colormode=='grayscale':\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img=np.expand_dims(img,axis=-1)\n",
    "  else:\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "  blob=cv2.resize(img,(width,height),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "  blob=np.expand_dims(blob,axis=0)*normalize_factor\n",
    "  arr=model.predict(blob)\n",
    "\n",
    "  valid_classes=[]\n",
    "\n",
    "\n",
    "  for batch in range(len(arr)):\n",
    "    \n",
    "    for i in range(grid_w):\n",
    "      \n",
    "      for j in range(grid_h):\n",
    "\n",
    "        confidence = arr[batch,i, j, 0, 0].squeeze()\n",
    "\n",
    "        if confidence>=0.5:\n",
    "          cx,cy,w,h=arr[batch,i, j, 0,1:5]\n",
    "          valid_classes.append(arr[batch,i, j, 0,1:5])\n",
    "          \n",
    "          cx = ((j + (cx)) / grid_size)\n",
    "          cy = ((i + (cy)) / grid_size)\n",
    "\n",
    "          cx=cx*img.shape[1]\n",
    "          cy=cy*img.shape[0]\n",
    "          w=w*img.shape[1]\n",
    "          h=h*img.shape[0]\n",
    "\n",
    "          \n",
    "\n",
    "          xmin=int(cx-(w/2))\n",
    "          ymin=int(cy-(h/2))\n",
    "          xmax=int(cx+(w/2))\n",
    "          ymax=int(cy+(h/2))\n",
    "\n",
    "\n",
    "          text=LABELS[int(np.argmax(arr[batch,i, j, 0, 5:]))]\n",
    "\n",
    "          cv2.rectangle(img, (int(xmin),int(ymin)), (int(xmax),int(ymax)), (0,0,255), 2)\n",
    "          cv2.putText(img, text, (int(cx) - 10, int(cy) - 10),cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,0,0), 1)\n",
    "\n",
    "  if len(valid_classes)==len(np.loadtxt(name).squeeze()):\n",
    "    pass\n",
    "\n",
    "  if colormode==\"grayscale\":\n",
    "    plt.imshow(img.squeeze(),cmap='gray')\n",
    "  else:\n",
    "    plt.imshow(img)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bVOen14E5c7x",
    "outputId": "68e01efa-e0f3-4bfb-dfc1-ae88d35a86b1"
   },
   "outputs": [],
   "source": [
    "for name in shuffle(train_fnames)[:10]:\n",
    "  \n",
    "  img=cv2.imread(name.replace('txt','jpg'))\n",
    "  if colormode=='grayscale':\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img=np.expand_dims(img,axis=-1)\n",
    "  else:\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "  blob=cv2.resize(img,(width,height),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "  blob=np.expand_dims(blob,axis=0)*normalize_factor\n",
    "  arr=model.predict(blob)\n",
    "\n",
    "  valid_classes=[]\n",
    "\n",
    "\n",
    "  for batch in range(len(arr)):\n",
    "    \n",
    "    for i in range(grid_w):\n",
    "      \n",
    "      for j in range(grid_h):\n",
    "\n",
    "        confidence = arr[batch,i, j, 0, 0].squeeze()\n",
    "\n",
    "        if confidence>=0.5:\n",
    "          cx,cy,w,h=arr[batch,i, j, 0,1:5]\n",
    "          valid_classes.append(arr[batch,i, j, 0,1:5])\n",
    "          \n",
    "          cx = ((j + (cx)) / grid_size)\n",
    "          cy = ((i + (cy)) / grid_size)\n",
    "\n",
    "          cx=cx*img.shape[1]\n",
    "          cy=cy*img.shape[0]\n",
    "          w=w*img.shape[1]\n",
    "          h=h*img.shape[0]\n",
    "\n",
    "          \n",
    "\n",
    "          xmin=int(cx-(w/2))\n",
    "          ymin=int(cy-(h/2))\n",
    "          xmax=int(cx+(w/2))\n",
    "          ymax=int(cy+(h/2))\n",
    "\n",
    "\n",
    "          text=LABELS[int(np.argmax(arr[batch,i, j, 0, 5:]))]\n",
    "\n",
    "          print(xmin,ymin,xmax,ymax)\n",
    "\n",
    "          cv2.rectangle(img, (int(xmin),int(ymin)), (int(xmax),int(ymax)), (0,0,255), 2)\n",
    "          cv2.putText(img, text, (int(cx) - 10, int(cy) - 10),cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,0,0), 1)\n",
    "\n",
    "  gt=np.loadtxt(name).squeeze()\n",
    "\n",
    "  if len(gt.shape)<2:\n",
    "    gt=np.expand_dims(gt,axis=0)\n",
    "\n",
    "  if len(valid_classes)==len(gt):\n",
    "    continue\n",
    "  #print(name,np.loadtxt(name).squeeze())\n",
    "  if colormode==\"grayscale\":\n",
    "    plt.imshow(img.squeeze(),cmap='gray')\n",
    "  else:\n",
    "    plt.imshow(img)\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "yolo_with_accuracy_mAP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
